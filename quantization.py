# -*- coding: utf-8 -*-
"""Quantization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D4A-axadyJiIUIWi9EPoTz82rxlZFmFu
"""

import torch
import torch.nn as nn
import torchvision.models as models
import numpy as np

def quantize_int4_per_channel(weight_tensor):

    # INT4 range
    qmin = -8
    qmax = 7

    # Ddtermine dimension for Conv2d and linear
    if len(weight_tensor.shape) == 4:
        # Conv2d: [out_channels, in_channels, kH, kW]
        dim = (1, 2, 3)
    elif len(weight_tensor.shape) == 2:
        # Linear: [out_features, in_features]
        dim = 1
    else:
        raise ValueError("Unsupported layer shape")

    # compute per-channel max absolute value
    max_abs = weight_tensor.abs().amax(dim=dim, keepdim=True)

    # compute scale per channel
    scale = max_abs / qmax
    scale[scale == 0] = 1e-8  # prevent division by zero

    # quantize
    q_weight = torch.round(weight_tensor / scale)
    q_weight = torch.clamp(q_weight, qmin, qmax)

    return q_weight.to(torch.int8), scale

def dequantize(q_weight, scale):
    return q_weight.float() * scale

def compute_mse(original, reconstructed):
    return torch.mean((original - reconstructed) ** 2).item()


def compute_memory_reduction(original_tensor, num_bits=4):
    original_bits = original_tensor.numel() * 32
    quantized_bits = original_tensor.numel() * num_bits
    reduction = 100 * (1 - quantized_bits / original_bits)
    return reduction

# linear layer
# load pretrained model
model = models.resnet18(pretrained=True)

linear_layer = model.fc
weights = linear_layer.weight.data.clone()

# quantize
q_weight, scale = quantize_int4_per_channel(weights)
reconstructed = dequantize(q_weight, scale)

# metrics
mse = compute_mse(weights, reconstructed)
memory_reduction = compute_memory_reduction(weights)

print("Linear Layer Results")
print("MSE:", mse)
print("Memory Reduction (%):", memory_reduction)

# conv2d layer
# load pretrained model
conv_layer = model.conv1
weights = conv_layer.weight.data.clone()

# quantize
q_weight, scale = quantize_int4_per_channel(weights)
reconstructed = dequantize(q_weight, scale)

# metrics
mse = compute_mse(weights, reconstructed)
memory_reduction = compute_memory_reduction(weights)

print("Conv2d Layer Results")
print("MSE:", mse)
print("Memory Reduction (%):", memory_reduction)